## 텍스트 전처리 (Text Preprocessing)
# 텍스트를 자연어 처리를 위해 용도에 맞도록 사전에 표준화하는 작업
# 텍스트 내 정보를 유지하고, 중복을 제거하여 분석 효율성을 높이기 위해 전처리를 수행

## 1. 토큰화(Tokenizing)
# 텍스트를 자연어 처리를 위해 분리 하는 것
# 토큰화는 단어별로 분리하는 "단어 토큰화(Word Tokenization)'와 문장별로 분리하는 "문장 토큰화(Sentence Tokenization)"로 구분
# 이후 실습에서는 단어 토큰화를 "토큰화'로 통일하여 칭하도록 한다.

# 준비하기--------------------------
text = '''인생은 모두가 함께하는 여행이다. 매일매일 사는 동안 우리가 할 수 있는 건 최선을 다해 이 멋진 여행을 만끽하는 것이다.'''

# 띄어 쓰기 토큰화하기--------------------------
#띄어쓰기로 토큰화
print(text.split(' '))
# 출력 값 : ['인생은', '모두가', '함께하는', '여행이다.', '매일매일', '사는', '동안', '우리가', '할', '수', '있는', '건', '최선을', '다해', '이', '멋진', '여행을', '만끽하는', '것이다.']

# 다양한 형태소 분석시를 사용해 토큰화 준비하기--------------------------
#필요하면 설치!
#pip install konlpy

# komoran(코모란) 준비하기--------------------------
# 코모란
from konlpy.tag import Komoran
komoran=Komoran()
# 토큰화: morphs
komoran_tokens = komoran.morphs(text)
print(komoran_tokens)
# 출력 값 : ['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '건', '최선', '을', '다', '하', '아', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']

# hannanum(한나눔) 준비하기 (KAIST 말뭉치)--------------------------
# 한나눔
from konlpy.tag import Hannanum
hannanum= Hannanum()
hannanum_tokens = hannanum.morphs(text)
print(hannanum_tokens)
# 출력 값 : ['인생', '은', '모두', '가', '함께하', '는', '여행', '이', '다', '.', '매일매일', '사', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '거', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']

# Okt(오크)준비하기(Open Korean Text) 트위터 형태소에 강함.--------------------------
# Okt
from konlpy.tag import Okt
okt = Okt()
okt_tokens = okt.morphs(text)
print(okt_tokens)
# 출력 값 : ['인생', '은', '모두', '가', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '가', '할', '수', '있는', '건', '최선', '을', '다해', '이', '멋진', '여행', '을', '만끽', '하는', '것', '이다', '.']

# Kkma(꼬꼬마) 준비하기--------------------------
# Kkma
from konlpy.tag import Kkma
Kkma = Kkma()
kkma_tokens = Kkma.morphs(text)
print(kkma_tokens)
# 출력 값 : ['인생', '은', '모두', '가', '함께', '하', '는', '여행', '이', '다', '.', '매일', '매일', '살', '는', '동안', '우리', '가', '하', 'ㄹ', '수', '있', '는', '것', '은', '최선', '을', '다하', '어', '이', '멋지', 'ㄴ', '여행', '을', '만끽', '하', '는', '것', '이', '다', '.']

## 2)붐사 부착(PoS Tagging)
# 각 토큰에 품사 정보를 추가
# 분석시에 불 필요한 품사를 제거 하거나(조사, 접속사 등)
# 필요한 품사를 필터맇 하기 위해

# komoran(코모란) 준비하기--------------------------
#코모란
komoranTag = []
for token in komoran_tokens :
    komoranTag += komoran.pos(token)
print(komoranTag)
# 출력 값 : [('인생', 'NNG'), ('은', 'NNP'), ('모두', 'MAG'), ('가', 'VV'), ('아', 'EC'), ('함께', 'MAG'), ('하', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('여행', 'NNG'), ('이', 'MM'), ('다', 'MAG'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'VV'), ('ㄹ', 'ETM'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'VV'), ('아', 'EC'), ('하', 'NNG'), ('ㄹ', 'NA'), ('수', 'NNB'), ('있', 'VV'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('건', 'NNB'), ('최선', 'NNP'), ('을', 'NNG'), ('다', 'MAG'), ('하', 'NNG'), ('아', 'IC'), ('이', 'MM'), ('멋', 'NNG'), ('지', 'NNB'), ('ㄴ', 'JX'), ('여행', 'NNG'), ('을', 'NNG'), ('만끽', 'NNP'), ('하', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('것', 'NNB'), ('이', 'MM'), ('다', 'MAG'), ('.', 'SF')]

# hannanum(한나눔) 준비하기 (KAIST 말뭉치)--------------------------
#한나눔
hannanumTag = []
for token in hannanum_tokens:
    hannanumTag += hannanum.pos(token)
print (hannanumTag)
# 출력 값 : [('인생', 'N'), ('은', 'N'), ('모두', 'M'), ('가', 'J'), ('함께하', 'P'), ('어', 'E'), ('늘', 'P'), ('ㄴ', 'E'), ('여행', 'N'), ('이', 'M'), ('다', 'M'), ('.', 'S'), ('매일매일', 'M'), ('사', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('동안', 'N'), ('우리', 'N'), ('가', 'J'), ('하', 'I'), ('ㄹ', 'N'), ('수', 'N'), ('있', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('것', 'N'), ('은', 'N'), ('최선', 'N'), ('을', 'N'), ('다하', 'P'), ('어', 'E'), ('어', 'N'), ('이', 'M'), ('멋지', 'N'), ('ㄴ', 'N'), ('여행', 'N'), ('을', 'N'), ('만끽', 'N'), ('하', 'I'), ('늘', 'P'), ('ㄴ', 'E'), ('것', 'N'), ('이', 'M'), ('다', 'M'), ('.', 'S')]

# Okt(오크)준비하기(Open Korean Text) 트위터 형태소에 강함.--------------------------
#Okt
oktTag = []
for token in okt_tokens:
    oktTag += okt.pos(token)
print (oktTag)
# 출력 값 : [('인생', 'Noun'), ('은', 'Noun'), ('모두', 'Noun'), ('가', 'Verb'), ('함께', 'Adverb'), ('하는', 'Verb'), ('여행', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation'), ('매', 'Noun'), ('일', 'Noun'), ('매일', 'Noun'), ('사는', 'Verb'), ('동안', 'Noun'), ('우리', 'Noun'), ('가', 'Verb'), ('할', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('건', 'Noun'), ('최선', 'Noun'), ('을', 'Josa'), ('다해', 'Noun'), ('이', 'Noun'), ('멋진', 'Adjective'), ('여행', 'Noun'), ('을', 'Josa'), ('만끽', 'Noun'), ('하는', 'Verb'), ('것', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation')]

# Kkma(꼬꼬마) 준비하기--------------------------
# Kkma
KkmaTag = []
for token in kkma_tokens:
    KkmaTag += Kkma.pos(token)
print (KkmaTag)
# 출력 값 : [('인생', 'NNG'), ('은', 'NNG'), ('모두', 'MAG'), ('가', 'NNG'), ('함께', 'MAG'), ('하', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('여행', 'NNG'), ('이', 'NNG'), ('다', 'NNG'), ('.', 'SF'), ('매일', 'MAG'), ('매일', 'MAG'), ('살', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('동안', 'NNG'), ('우리', 'NP'), ('가', 'NNG'), ('하', 'NNG'), ('ㄹ', 'NNG'), ('수', 'NNG'), ('있', 'VA'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('것', 'NNB'), ('은', 'NNG'), ('최선', 'NNG'), ('을', 'NNG'), ('다하', 'VV'), ('어', 'NNG'), ('이', 'NNG'), ('멋지', 'VA'), ('ㄴ', 'NNG'), ('여행', 'NNG'), ('을', 'NNG'), ('만끽', 'NNG'), ('하', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('것', 'NNB'), ('이', 'NNG'), ('다', 'NNG'), ('.', 'SF')]

## 불용어처리(Stopword)
# 자연어 처리를 위해 불필요한 요소를 제거하는 작업
# 불필요한 품사를 제거하는 작업과 불필요한 단어를 제거하는 작업으로 구성
# 불필요한 토큰을 제거 하여 연산의 효용성을 높임

#twitter
#최빈어 조회, 최빈어를 조회하여 불용어 제거 대상을 선정
from collections import Counter
Counter(oktTag).most_common()

#불용어 처리
stopPos = ['Jo','Pu','Su','Fo','Al','Nu']
stopWord = ['을','은','가', '는']

word = []
for tag in oktTag:
    if tag[1] not in stopPos:
        if tag[0] not in stopWord:
            word.append(tag[0])

print(word)
#출력 값 : ['인생', '모두', '함께', '하는', '여행', '이다', '.', '매', '일', '매일', '사는', '동안', '우리', '할', '수', '있는', '건', '최선', '다해', '이', '멋진', '여행', '만끽', '하는', '것', '이다', '.']